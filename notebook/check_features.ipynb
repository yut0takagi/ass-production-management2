{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0e491d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import itertools\n",
    "import random\n",
    "from IPython.display import display\n",
    "\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from tools.get_describe_record import get_describe_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfa4e420",
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresA = [f\"X{i}\" for i in range(24, 61)]\n",
    "#featuresB = [f\"X{i}\" for i in range(1, 84)]\n",
    "\n",
    "#featuresA = ['X3', 'X54', 'X68', 'X78']\n",
    "featuresB = ['X2', 'X24', 'X33', 'X37']\n",
    "\n",
    "comb_A = itertools.combinations(featuresA, 7)\n",
    "comb_B = itertools.combinations(featuresB, 4)\n",
    "\n",
    "comb_AB = list(itertools.product(comb_A, comb_B))\n",
    "random.shuffle(comb_AB)\n",
    "\n",
    "best_rmse = 100\n",
    "rmse_sp = 100\n",
    "rmse_no = 100\n",
    "rmse_all = 100\n",
    "\n",
    "best_rmse_sp = 100\n",
    "best_rmse_no = 100\n",
    "\n",
    "best_comb = None\n",
    "\n",
    "# 異常スパイク検出用\n",
    "batch_describe_df = pd.read_csv(\"../data/processed/batch_describe_df.csv\")\n",
    "test_batch = batch_describe_df.iloc[75:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c47ccc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spike_batches: [84, 89, 90, 92, 93, 94, 95]\n",
      "normal_batches: [75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 87, 88, 91, 96, 97, 98, 99]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>process_end_time</th>\n",
       "      <th>final_mes_time</th>\n",
       "      <th>OV</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>...</th>\n",
       "      <th>X77</th>\n",
       "      <th>X78</th>\n",
       "      <th>X79</th>\n",
       "      <th>X80</th>\n",
       "      <th>X81</th>\n",
       "      <th>X82</th>\n",
       "      <th>X83</th>\n",
       "      <th>batch_id</th>\n",
       "      <th>batch_OV_std</th>\n",
       "      <th>is_anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2016-09-05 07:02:00</td>\n",
       "      <td>2016-10-10 16:10:00</td>\n",
       "      <td>232.76840</td>\n",
       "      <td>23.12</td>\n",
       "      <td>2.79</td>\n",
       "      <td>982.97</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.08</td>\n",
       "      <td>419.87</td>\n",
       "      <td>...</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.03</td>\n",
       "      <td>2</td>\n",
       "      <td>18.030431</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2016-09-05 07:02:00</td>\n",
       "      <td>2016-10-10 21:53:00</td>\n",
       "      <td>203.99410</td>\n",
       "      <td>23.12</td>\n",
       "      <td>2.79</td>\n",
       "      <td>982.97</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.08</td>\n",
       "      <td>419.87</td>\n",
       "      <td>...</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.03</td>\n",
       "      <td>2</td>\n",
       "      <td>18.030431</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>2016-09-05 07:02:00</td>\n",
       "      <td>2016-10-11 02:24:00</td>\n",
       "      <td>214.65380</td>\n",
       "      <td>23.12</td>\n",
       "      <td>2.79</td>\n",
       "      <td>982.97</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.08</td>\n",
       "      <td>419.87</td>\n",
       "      <td>...</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.03</td>\n",
       "      <td>2</td>\n",
       "      <td>18.030431</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>2016-09-05 07:02:00</td>\n",
       "      <td>2016-10-11 07:10:00</td>\n",
       "      <td>189.10500</td>\n",
       "      <td>23.12</td>\n",
       "      <td>2.79</td>\n",
       "      <td>982.97</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.08</td>\n",
       "      <td>419.87</td>\n",
       "      <td>...</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.03</td>\n",
       "      <td>2</td>\n",
       "      <td>18.030431</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2016-09-05 07:02:00</td>\n",
       "      <td>2016-10-11 11:16:00</td>\n",
       "      <td>198.91220</td>\n",
       "      <td>23.12</td>\n",
       "      <td>2.79</td>\n",
       "      <td>982.97</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.08</td>\n",
       "      <td>419.87</td>\n",
       "      <td>...</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.03</td>\n",
       "      <td>2</td>\n",
       "      <td>18.030431</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1761</th>\n",
       "      <td>2016-11-27 02:23:00</td>\n",
       "      <td>2017-01-13 00:47:00</td>\n",
       "      <td>82.84555</td>\n",
       "      <td>23.62</td>\n",
       "      <td>9.35</td>\n",
       "      <td>705.91</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.08</td>\n",
       "      <td>127.48</td>\n",
       "      <td>...</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.04</td>\n",
       "      <td>74</td>\n",
       "      <td>17.281147</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>2016-11-27 02:23:00</td>\n",
       "      <td>2017-01-13 02:04:00</td>\n",
       "      <td>78.26471</td>\n",
       "      <td>24.35</td>\n",
       "      <td>4.92</td>\n",
       "      <td>635.52</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.09</td>\n",
       "      <td>78.09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.04</td>\n",
       "      <td>74</td>\n",
       "      <td>17.281147</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1763</th>\n",
       "      <td>2016-11-27 02:23:00</td>\n",
       "      <td>2017-01-13 04:58:00</td>\n",
       "      <td>101.99680</td>\n",
       "      <td>24.35</td>\n",
       "      <td>4.92</td>\n",
       "      <td>635.52</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.09</td>\n",
       "      <td>78.09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.04</td>\n",
       "      <td>74</td>\n",
       "      <td>17.281147</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764</th>\n",
       "      <td>2016-11-27 02:23:00</td>\n",
       "      <td>2017-01-13 06:08:00</td>\n",
       "      <td>90.90938</td>\n",
       "      <td>23.62</td>\n",
       "      <td>9.35</td>\n",
       "      <td>705.91</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.08</td>\n",
       "      <td>127.48</td>\n",
       "      <td>...</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.04</td>\n",
       "      <td>74</td>\n",
       "      <td>17.281147</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1765</th>\n",
       "      <td>2016-11-27 02:23:00</td>\n",
       "      <td>2017-01-13 09:08:00</td>\n",
       "      <td>102.07970</td>\n",
       "      <td>23.62</td>\n",
       "      <td>9.35</td>\n",
       "      <td>705.91</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.08</td>\n",
       "      <td>127.48</td>\n",
       "      <td>...</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.04</td>\n",
       "      <td>74</td>\n",
       "      <td>17.281147</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1466 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         process_end_time       final_mes_time         OV     X1    X2  \\\n",
       "75    2016-09-05 07:02:00  2016-10-10 16:10:00  232.76840  23.12  2.79   \n",
       "76    2016-09-05 07:02:00  2016-10-10 21:53:00  203.99410  23.12  2.79   \n",
       "77    2016-09-05 07:02:00  2016-10-11 02:24:00  214.65380  23.12  2.79   \n",
       "78    2016-09-05 07:02:00  2016-10-11 07:10:00  189.10500  23.12  2.79   \n",
       "79    2016-09-05 07:02:00  2016-10-11 11:16:00  198.91220  23.12  2.79   \n",
       "...                   ...                  ...        ...    ...   ...   \n",
       "1761  2016-11-27 02:23:00  2017-01-13 00:47:00   82.84555  23.62  9.35   \n",
       "1762  2016-11-27 02:23:00  2017-01-13 02:04:00   78.26471  24.35  4.92   \n",
       "1763  2016-11-27 02:23:00  2017-01-13 04:58:00  101.99680  24.35  4.92   \n",
       "1764  2016-11-27 02:23:00  2017-01-13 06:08:00   90.90938  23.62  9.35   \n",
       "1765  2016-11-27 02:23:00  2017-01-13 09:08:00  102.07970  23.62  9.35   \n",
       "\n",
       "          X3    X4    X5    X6      X7  ...   X77  X78  X79   X80   X81   X82  \\\n",
       "75    982.97  0.89  0.16  0.08  419.87  ...  0.18  0.0  5.9  0.00  0.03  0.19   \n",
       "76    982.97  0.89  0.16  0.08  419.87  ...  0.18  0.0  5.9  0.00  0.03  0.19   \n",
       "77    982.97  0.89  0.16  0.08  419.87  ...  0.18  0.0  5.9  0.00  0.03  0.19   \n",
       "78    982.97  0.89  0.16  0.08  419.87  ...  0.18  0.0  5.9  0.00  0.03  0.19   \n",
       "79    982.97  0.89  0.16  0.08  419.87  ...  0.18  0.0  5.9  0.00  0.03  0.19   \n",
       "...      ...   ...   ...   ...     ...  ...   ...  ...  ...   ...   ...   ...   \n",
       "1761  705.91  0.64  0.14  0.08  127.48  ...  0.20  0.0  2.7  0.02  0.01  0.25   \n",
       "1762  635.52  0.64  0.14  0.09   78.09  ...  0.20  0.0  2.7  0.02  0.01  0.25   \n",
       "1763  635.52  0.64  0.14  0.09   78.09  ...  0.20  0.0  2.7  0.02  0.01  0.25   \n",
       "1764  705.91  0.64  0.14  0.08  127.48  ...  0.20  0.0  2.7  0.02  0.01  0.25   \n",
       "1765  705.91  0.64  0.14  0.08  127.48  ...  0.20  0.0  2.7  0.02  0.01  0.25   \n",
       "\n",
       "       X83  batch_id  batch_OV_std  is_anomaly  \n",
       "75    0.03         2     18.030431           0  \n",
       "76    0.03         2     18.030431           0  \n",
       "77    0.03         2     18.030431           0  \n",
       "78    0.03         2     18.030431           0  \n",
       "79    0.03         2     18.030431           0  \n",
       "...    ...       ...           ...         ...  \n",
       "1761  0.04        74     17.281147           0  \n",
       "1762  0.04        74     17.281147           0  \n",
       "1763  0.04        74     17.281147           0  \n",
       "1764  0.04        74     17.281147           0  \n",
       "1765  0.04        74     17.281147           0  \n",
       "\n",
       "[1466 rows x 89 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# 異常スパイク検知モデルと閾値スコアの読み込み\n",
    "with open(\"../data/model/spike_detection_IFmodel.pkl\", \"rb\") as f:\n",
    "    spike_detection_model = pickle.load(f)\n",
    "with open(\"../data/score/IF_train_score.pkl\", \"rb\") as f:\n",
    "    spike_detection_score = pickle.load(f)\n",
    "thr = np.quantile(spike_detection_score, 0.90)\n",
    "\n",
    "score_test  = -spike_detection_model.score_samples(test_batch)\n",
    "pred_iso = (score_test >= thr).astype(int)\n",
    "spike_batches = test_batch.index[pred_iso == 1].tolist()\n",
    "normal_batches = test_batch.index[pred_iso == 0].tolist()\n",
    "print(f\"spike_batches: {spike_batches}\")\n",
    "print(f\"normal_batches: {normal_batches}\")\n",
    "\n",
    "\n",
    "# 学習用データ\n",
    "tagged_data = pd.read_csv(\"../data/processed/processe_tagged_anormaly.csv\")\n",
    "anomaly_df = tagged_data[tagged_data[\"is_anomaly\"] == 1]\n",
    "normal_df = tagged_data[tagged_data[\"is_anomaly\"] == 0]\n",
    "#display(normal_df)\n",
    "anomaly_train_df = anomaly_df[anomaly_df[\"batch_id\"] < 75]\n",
    "nomaly_train_df = normal_df[normal_df[\"batch_id\"] < 75]\n",
    "display(nomaly_train_df)\n",
    "\n",
    "# テスト用データ\n",
    "test_df = pd.read_csv(\"../data/processed/processe_tagged_anormaly.csv\")\n",
    "anomaly_test_df = test_df[test_df[\"batch_id\"].isin(spike_batches)]\n",
    "normaly_test_df  = test_df[test_df[\"batch_id\"].isin(normal_batches)]\n",
    "test_df_original = test_df[test_df[\"batch_id\"] >=75]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcdb8f3",
   "metadata": {},
   "source": [
    "## 特徴量エンジニアリング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d130eecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量エンジニアリング\n",
    "def feature_engineering1(\n",
    "    df,\n",
    "    SENSOR_COLS,\n",
    "    LAGS,\n",
    "    WINS\n",
    "    ):\n",
    "    base = df[SENSOR_COLS].copy()\n",
    "    feats = {}  # ★ここに全部貯める\n",
    "\n",
    "    for c in SENSOR_COLS:\n",
    "        s = df[c]\n",
    "\n",
    "        #std\n",
    "        feats[f\"{c}_std5\"] = s.rolling(5, min_periods=1).std()\n",
    "        feats[f\"{c}_std10\"] = s.rolling(10, min_periods=1).std()\n",
    "        \n",
    "        # lag\n",
    "        for l in LAGS:\n",
    "            feats[f\"{c}_lag{l}\"] = s.shift(l)\n",
    "\n",
    "        # diff / pct\n",
    "        feats[f\"{c}_diff1\"] = s.diff(1)\n",
    "        feats[f\"{c}_diff2\"] = s.diff(2)\n",
    "        feats[f\"{c}_diff3\"] = s.diff(3)\n",
    "        feats[f\"{c}_pct1\"]  = s.pct_change(1).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "        # rolling\n",
    "        for w in WINS:\n",
    "            r = s.rolling(w, min_periods=1)\n",
    "            rmean = r.mean()\n",
    "            rstd  = r.std()\n",
    "            feats[f\"{c}_rmean{w}\"] = rmean\n",
    "            feats[f\"{c}_rstd{w}\"]  = rstd\n",
    "            feats[f\"{c}_rmax{w}\"]  = r.max()\n",
    "            feats[f\"{c}_rmin{w}\"]  = r.min()\n",
    "            feats[f\"{c}_z{w}\"]     = (s - rmean) / (rstd + 1e-9)\n",
    "            feats[f\"{c}_dev{w}\"]   = s - rmean\n",
    "        \n",
    "        feats[f\"{c}_energy\"] = (\n",
    "            feats[f\"{c}_rstd20\"] * feats[f\"{c}_rmax20\"]\n",
    "        )\n",
    "\n",
    "        feats[f\"{c}_jump\"] = s - s.shift(5)\n",
    "\n",
    "    feat_df = pd.concat([base, pd.DataFrame(feats, index=df.index)], axis=1)\n",
    "    feat_df = feat_df.ffill().bfill().fillna(0)\n",
    "    return feat_df\n",
    "\n",
    "\n",
    "def df_set_datetime(df, col_names):\n",
    "    df = df.copy()\n",
    "    for col in col_names:\n",
    "        df[col] = pd.to_datetime(df[col])\n",
    "    return df\n",
    "\n",
    "def get_elapsed_day(df, base_time=None, col=\"process_end_time\"):\n",
    "    df = df.copy()\n",
    "    if base_time is None:\n",
    "        base_time = df[col].min()\n",
    "    df[\"elapsed_day\"] = (df[col] - base_time).dt.total_seconds() / (3600 * 24)\n",
    "    return df\n",
    "\n",
    "def add_time_features(df, time_col=\"process_end_time\"):\n",
    "    \"\"\"周期性（曜日・時間帯）を入れたいとき用。不要なら呼ばなくてOK\"\"\"\n",
    "    df = df.copy()\n",
    "    t = df[time_col]\n",
    "    df[\"dow\"] = t.dt.dayofweek              # 0=Mon\n",
    "    df[\"hour\"] = t.dt.hour\n",
    "\n",
    "    # 周期は sin/cos にすると学習しやすい\n",
    "    df[\"dow_sin\"]  = np.sin(2*np.pi*df[\"dow\"]/7)\n",
    "    df[\"dow_cos\"]  = np.cos(2*np.pi*df[\"dow\"]/7)\n",
    "    df[\"hour_sin\"] = np.sin(2*np.pi*df[\"hour\"]/24)\n",
    "    df[\"hour_cos\"] = np.cos(2*np.pi*df[\"hour\"]/24)\n",
    "    return df\n",
    "\n",
    "def add_duration_features(df, start_col=\"process_end_time\", end_col=\"final_mes_time\"):\n",
    "    \"\"\"工程時間（測定完了までの所要）\"\"\"\n",
    "    df = df.copy()\n",
    "    dur = (df[end_col] - df[start_col]).dt.total_seconds()\n",
    "    df[\"duration_sec\"] = dur\n",
    "    df[\"duration_log1p\"] = np.log1p(np.clip(dur, 0, None))\n",
    "    return df\n",
    "\n",
    "def add_ov_features(\n",
    "    df,\n",
    "    target=\"OV\",\n",
    "    lags=(1, 2, 3, 10),\n",
    "    wins=(3, 5, 10, 20),\n",
    "    ema_spans=(2, 5, 10, 20)\n",
    "):\n",
    "    \"\"\"\n",
    "    重要：リーク防止のため “すべて1ステップ前まで” を使う\n",
    "    → lagはshift(l)、rolling/emaはshift(1)\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    y = df[target]\n",
    "\n",
    "    # lag\n",
    "    for l in lags:\n",
    "        df[f\"{target}_lag{l}\"] = y.shift(l)\n",
    "\n",
    "    # diff（1つ前までしか見ない）\n",
    "    df[f\"{target}_diff1\"] = y.diff(1).shift(1)\n",
    "    df[f\"{target}_diff2\"] = y.diff(2).shift(1)\n",
    "\n",
    "    # rolling stats（1つ前まで）\n",
    "    for w in wins:\n",
    "        r = y.rolling(w, min_periods=1)\n",
    "        mean = r.mean().shift(1)\n",
    "        std  = r.std().shift(1)\n",
    "        mx   = r.max().shift(1)\n",
    "        mn   = r.min().shift(1)\n",
    "\n",
    "        df[f\"{target}_roll_mean{w}\"] = mean\n",
    "        df[f\"{target}_roll_std{w}\"]  = std\n",
    "        df[f\"{target}_roll_max{w}\"]  = mx\n",
    "        df[f\"{target}_roll_min{w}\"]  = mn\n",
    "        df[f\"{target}_dev{w}\"]       = y.shift(1) - mean\n",
    "        df[f\"{target}_z{w}\"]         = (y.shift(1) - mean) / (std + 1e-9)\n",
    "\n",
    "        # 窓内レンジ（スパイク気配）\n",
    "        df[f\"{target}_range{w}\"]     = mx - mn\n",
    "\n",
    "    # EMA（指数移動平均、反応が速い）\n",
    "    for s in ema_spans:\n",
    "        ema = y.ewm(span=s, adjust=False).mean().shift(1)\n",
    "        df[f\"{target}_ema{s}\"] = ema\n",
    "        df[f\"{target}_ema_dev{s}\"] = y.shift(1) - ema\n",
    "\n",
    "    # “短期荒れ / 長期荒れ” 比（スパイク前兆に刺さりやすい）\n",
    "    if 5 in wins and 20 in wins:\n",
    "        df[f\"{target}_std_ratio_5_20\"] = df[f\"{target}_roll_std5\"] / (df[f\"{target}_roll_std20\"] + 1e-9)\n",
    "\n",
    "    return df\n",
    "\n",
    "def add_ov_batch_features(df, target=\"OV\", batch_col=\"batch_id\", wins=(3,5,10,20)):\n",
    "    df = df.copy()\n",
    "    df = df.sort_values([\"process_end_time\", \"final_mes_time\"]).reset_index(drop=True)\n",
    "\n",
    "    g = df.groupby(batch_col, sort=False)[target]\n",
    "\n",
    "    # バッチ内の「何番目か」\n",
    "    df[\"pos_in_batch\"] = g.cumcount()  # 0,1,2,...\n",
    "\n",
    "    # バッチ内の過去だけで作る累積統計（expanding）※ shift(1) が肝\n",
    "    past = g.shift(1)\n",
    "\n",
    "    df[f\"{target}_batch_exp_mean\"] = past.groupby(df[batch_col]).expanding().mean().reset_index(level=0, drop=True)\n",
    "    df[f\"{target}_batch_exp_std\"]  = past.groupby(df[batch_col]).expanding().std().reset_index(level=0, drop=True)\n",
    "    df[f\"{target}_batch_exp_max\"]  = past.groupby(df[batch_col]).expanding().max().reset_index(level=0, drop=True)\n",
    "    df[f\"{target}_batch_exp_min\"]  = past.groupby(df[batch_col]).expanding().min().reset_index(level=0, drop=True)\n",
    "\n",
    "    # バッチ内rolling（直近w点）も過去だけで\n",
    "    for w in wins:\n",
    "        df[f\"{target}_batch_roll_mean{w}\"] = g.shift(1).rolling(w, min_periods=1).mean()\n",
    "        df[f\"{target}_batch_roll_std{w}\"]  = g.shift(1).rolling(w, min_periods=1).std()\n",
    "        df[f\"{target}_batch_roll_max{w}\"]  = g.shift(1).rolling(w, min_periods=1).max()\n",
    "        df[f\"{target}_batch_roll_min{w}\"]  = g.shift(1).rolling(w, min_periods=1).min()\n",
    "\n",
    "    # 欠損は ffill せず、0埋め or 明示的に埋め（初期は過去がないので）\n",
    "    df = df.fillna(0)\n",
    "    return df\n",
    "\n",
    "def feature_engineering2(\n",
    "    df,\n",
    "    normal_features,\n",
    "    target=\"OV\",\n",
    "    lags=(1,2,3,5,10),\n",
    "    wins=(3,5,10,20),\n",
    "    ema_spans=(2,5,10,20),\n",
    "    use_time_features=False\n",
    "):\n",
    "    df = df.copy()\n",
    "    df = df_set_datetime(df, [\"process_end_time\", \"final_mes_time\"])\n",
    "    df = df.sort_values([\"process_end_time\", \"final_mes_time\"]).reset_index(drop=True)\n",
    "\n",
    "    df = get_elapsed_day(df, col=\"process_end_time\")\n",
    "    df = add_duration_features(df, \"process_end_time\", \"final_mes_time\")\n",
    "    if use_time_features:\n",
    "        df = add_time_features(df, \"process_end_time\")\n",
    "\n",
    "    # 既存：OVの過去特徴量（リークなし）\n",
    "    df = add_ov_features(df, target=target, lags=lags, wins=wins, ema_spans=ema_spans)\n",
    "\n",
    "    # 追加：batch内の過去統計（リークなし）\n",
    "    if \"batch_id\" in df.columns:\n",
    "        df = add_ov_batch_features(df, target=target, batch_col=\"batch_id\", wins=wins)\n",
    "\n",
    "    # 欠損処理：時系列は基本ffillのみ（bfillは未来リークの可能性）\n",
    "    df = df.ffill().fillna(0)\n",
    "\n",
    "    # 必要列だけ\n",
    "    df = df.drop(columns=[c for c in df.columns if c not in normal_features])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ba63aa",
   "metadata": {},
   "source": [
    "## 変数重み付け, fit, モデル評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0307ab36",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'HAS_LGBM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 102\u001b[39m\n\u001b[32m     99\u001b[39m results = []\n\u001b[32m    100\u001b[39m pred_store = {}\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m candidates = \u001b[43mget_candidate_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m candidates.items():\n\u001b[32m    104\u001b[39m     rmse, pred = fit_predict_rmse(\n\u001b[32m    105\u001b[39m         model=model,\n\u001b[32m    106\u001b[39m         X_train=X_sp, y_train_raw=y_sp_raw,\n\u001b[32m   (...)\u001b[39m\u001b[32m    109\u001b[39m         model_name=name\n\u001b[32m    110\u001b[39m     )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 69\u001b[39m, in \u001b[36mget_candidate_models\u001b[39m\u001b[34m(random_state)\u001b[39m\n\u001b[32m     63\u001b[39m models[\u001b[33m\"\u001b[39m\u001b[33mHuberReg\u001b[39m\u001b[33m\"\u001b[39m] = Pipeline([\n\u001b[32m     64\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33mscaler\u001b[39m\u001b[33m\"\u001b[39m, StandardScaler(with_mean=\u001b[38;5;28;01mFalse\u001b[39;00m)),  \u001b[38;5;66;03m# sparseでも安全\u001b[39;00m\n\u001b[32m     65\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33mhuber\u001b[39m\u001b[33m\"\u001b[39m, HuberRegressor(epsilon=\u001b[32m1.35\u001b[39m, alpha=\u001b[32m1e-4\u001b[39m))\n\u001b[32m     66\u001b[39m ])\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# 6) LightGBM（使えるなら最有力）\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mHAS_LGBM\u001b[49m:\n\u001b[32m     70\u001b[39m     models[\u001b[33m\"\u001b[39m\u001b[33mLGBM\u001b[39m\u001b[33m\"\u001b[39m] = LGBMRegressor(\n\u001b[32m     71\u001b[39m         objective=\u001b[33m\"\u001b[39m\u001b[33mregression\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     72\u001b[39m         n_estimators=\u001b[32m4000\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     81\u001b[39m         n_jobs=-\u001b[32m1\u001b[39m\n\u001b[32m     82\u001b[39m     )\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m models\n",
      "\u001b[31mNameError\u001b[39m: name 'HAS_LGBM' is not defined"
     ]
    }
   ],
   "source": [
    "def make_spike_weights(y_raw: np.ndarray, q_percentile=90, power=3):\n",
    "    \"\"\"高OVを重くする重み（あなたのロジックを関数化）\"\"\"\n",
    "    q = np.percentile(y_raw, q_percentile)\n",
    "    w = np.ones_like(y_raw, dtype=float)\n",
    "    hi = (y_raw >= q)\n",
    "    w[hi] = 1 + ((y_raw[hi] / (q + 1e-9)) ** power)\n",
    "    w = np.clip(w, 1.0, np.percentile(w, 95))\n",
    "    return w\n",
    "\n",
    "\n",
    "def fit_predict_rmse(\n",
    "    model,\n",
    "    X_train, y_train_raw,\n",
    "    X_test, y_test_raw,\n",
    "    sample_weight=None,\n",
    "    model_name=\"model\",\n",
    "):\n",
    "    \"\"\"log1p学習 → expm1で元スケールに戻してRMSE\"\"\"\n",
    "    y_train = np.log1p(y_train_raw)\n",
    "\n",
    "    # fit（sample_weight に対応していないモデルは例外になるので分岐）\n",
    "    try:\n",
    "        model.fit(X_train, y_train, sample_weight=sample_weight)\n",
    "    except TypeError:\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "    pred_log = model.predict(X_test)\n",
    "    pred = np.expm1(pred_log)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_raw, pred))\n",
    "    return rmse, pred\n",
    "\n",
    "def get_candidate_models(random_state=42):\n",
    "    models = {}\n",
    "\n",
    "    # 1) RandomForest（現状）\n",
    "    models[\"RF_1500_d18\"] = RandomForestRegressor(\n",
    "        n_estimators=1500, max_depth=18, min_samples_leaf=1,\n",
    "        random_state=random_state, n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # 2) ExtraTrees（RFよりスパイクに強いことが多い）\n",
    "    models[\"ET_2000\"] = ExtraTreesRegressor(\n",
    "        n_estimators=2000, max_depth=None, min_samples_leaf=1,\n",
    "        random_state=random_state, n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # 3) GradientBoosting（古典GBDTだが堅い）\n",
    "    # sample_weight 対応あり\n",
    "    models[\"GBR_Huber\"] = GradientBoostingRegressor(\n",
    "        loss=\"huber\", n_estimators=600, learning_rate=0.05,\n",
    "        max_depth=3, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # 4) HistGradientBoosting（高速GBDT）\n",
    "    # ※ sample_weight は sklearn の版によって挙動差があるので、渡せない場合は自動で無視される\n",
    "    models[\"HGBR\"] = HistGradientBoostingRegressor(\n",
    "        max_depth=6, learning_rate=0.05, max_iter=800,\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    # 5) Huber回帰（ロバスト。スケーリング必須）\n",
    "    models[\"HuberReg\"] = Pipeline([\n",
    "        (\"scaler\", StandardScaler(with_mean=False)),  # sparseでも安全\n",
    "        (\"huber\", HuberRegressor(epsilon=1.35, alpha=1e-4))\n",
    "    ])\n",
    "\n",
    "    # 6) LightGBM\n",
    "    models[\"LGBM\"] = LGBMRegressor(\n",
    "        objective=\"regression\",\n",
    "        n_estimators=4000,\n",
    "        learning_rate=0.03,\n",
    "        num_leaves=63,\n",
    "        max_depth=-1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha=0.0,\n",
    "        reg_lambda=0.0,\n",
    "        random_state=random_state,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    return models\n",
    "\n",
    "\n",
    "# ---- 実行部（あなたの特徴量生成に接続） ----\n",
    "# train_feature_df = feature_engineering1(...)\n",
    "# test_feature_df  = feature_engineering1(...)\n",
    "\n",
    "X_sp = train_feature_df\n",
    "y_sp_raw = anomaly_train_df[\"OV\"].values\n",
    "\n",
    "X_te = test_feature_df\n",
    "y_te_raw = anomaly_test_df[\"OV\"].values\n",
    "\n",
    "w = make_spike_weights(y_sp_raw, q_percentile=90, power=3)\n",
    "\n",
    "results = []\n",
    "pred_store = {}\n",
    "\n",
    "candidates = get_candidate_models(random_state=42)\n",
    "for name, model in candidates.items():\n",
    "    rmse, pred = fit_predict_rmse(\n",
    "        model=model,\n",
    "        X_train=X_sp, y_train_raw=y_sp_raw,\n",
    "        X_test=X_te, y_test_raw=y_te_raw,\n",
    "        sample_weight=w,  # 渡せないモデルは内部で自動スキップ\n",
    "        model_name=name\n",
    "    )\n",
    "    results.append((name, rmse))\n",
    "    pred_store[name] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d41200c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMB:(('X24', 'X27', 'X45', 'X47', 'X48', 'X54', 'X59'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 51.881 \t RMSE (SP): 87.243 \t RMSE (NO): 24.947 \t RMSE BEST: 100.000\t100.000\t100.000\n",
      "BEST MODEL FOUND\n",
      "COMB:(('X24', 'X31', 'X48', 'X49', 'X53', 'X56', 'X59'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 64.520 \t RMSE (SP): 112.162 \t RMSE (NO): 24.947 \t RMSE BEST: 51.881\t87.243\t24.947\n",
      "COMB:(('X31', 'X40', 'X44', 'X45', 'X48', 'X50', 'X54'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 57.734 \t RMSE (SP): 98.885 \t RMSE (NO): 24.947 \t RMSE BEST: 51.881\t87.243\t24.947\n",
      "COMB:(('X31', 'X34', 'X35', 'X36', 'X39', 'X45', 'X50'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 54.094 \t RMSE (SP): 91.671 \t RMSE (NO): 24.947 \t RMSE BEST: 51.881\t87.243\t24.947\n",
      "COMB:(('X25', 'X29', 'X39', 'X43', 'X50', 'X55', 'X59'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 46.628 \t RMSE (SP): 76.574 \t RMSE (NO): 24.947 \t RMSE BEST: 51.881\t87.243\t24.947\n",
      "BEST MODEL FOUND\n",
      "COMB:(('X29', 'X35', 'X42', 'X44', 'X54', 'X59', 'X60'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 57.986 \t RMSE (SP): 99.383 \t RMSE (NO): 24.947 \t RMSE BEST: 46.628\t76.574\t24.947\n",
      "COMB:(('X35', 'X37', 'X40', 'X47', 'X51', 'X52', 'X54'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 58.934 \t RMSE (SP): 101.248 \t RMSE (NO): 24.947 \t RMSE BEST: 46.628\t76.574\t24.947\n",
      "COMB:(('X24', 'X32', 'X34', 'X45', 'X48', 'X52', 'X54'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 58.266 \t RMSE (SP): 99.934 \t RMSE (NO): 24.947 \t RMSE BEST: 46.628\t76.574\t24.947\n",
      "COMB:(('X25', 'X28', 'X32', 'X35', 'X40', 'X50', 'X54'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 50.386 \t RMSE (SP): 84.232 \t RMSE (NO): 24.947 \t RMSE BEST: 46.628\t76.574\t24.947\n",
      "COMB:(('X27', 'X30', 'X32', 'X36', 'X49', 'X51', 'X53'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 46.807 \t RMSE (SP): 76.943 \t RMSE (NO): 24.947 \t RMSE BEST: 46.628\t76.574\t24.947\n",
      "COMB:(('X27', 'X29', 'X31', 'X33', 'X45', 'X48', 'X51'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 72.230 \t RMSE (SP): 127.049 \t RMSE (NO): 24.947 \t RMSE BEST: 46.628\t76.574\t24.947\n",
      "COMB:(('X29', 'X37', 'X51', 'X53', 'X54', 'X57', 'X58'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 57.170 \t RMSE (SP): 97.772 \t RMSE (NO): 24.947 \t RMSE BEST: 46.628\t76.574\t24.947\n",
      "COMB:(('X26', 'X33', 'X35', 'X40', 'X46', 'X54', 'X55'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 72.471 \t RMSE (SP): 127.512 \t RMSE (NO): 24.947 \t RMSE BEST: 46.628\t76.574\t24.947\n",
      "COMB:(('X26', 'X30', 'X34', 'X35', 'X40', 'X49', 'X54'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 46.959 \t RMSE (SP): 77.254 \t RMSE (NO): 24.947 \t RMSE BEST: 46.628\t76.574\t24.947\n",
      "COMB:(('X24', 'X41', 'X44', 'X49', 'X50', 'X59', 'X60'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 66.821 \t RMSE (SP): 116.624 \t RMSE (NO): 24.947 \t RMSE BEST: 46.628\t76.574\t24.947\n",
      "COMB:(('X31', 'X32', 'X35', 'X46', 'X47', 'X52', 'X60'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 54.728 \t RMSE (SP): 92.934 \t RMSE (NO): 24.947 \t RMSE BEST: 46.628\t76.574\t24.947\n",
      "COMB:(('X24', 'X36', 'X46', 'X51', 'X54', 'X57', 'X58'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 64.715 \t RMSE (SP): 112.542 \t RMSE (NO): 24.947 \t RMSE BEST: 46.628\t76.574\t24.947\n",
      "COMB:(('X31', 'X32', 'X42', 'X43', 'X48', 'X57', 'X59'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 58.261 \t RMSE (SP): 99.924 \t RMSE (NO): 24.947 \t RMSE BEST: 46.628\t76.574\t24.947\n",
      "COMB:(('X25', 'X29', 'X30', 'X32', 'X46', 'X50', 'X57'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 46.996 \t RMSE (SP): 77.331 \t RMSE (NO): 24.947 \t RMSE BEST: 46.628\t76.574\t24.947\n",
      "COMB:(('X24', 'X25', 'X29', 'X40', 'X46', 'X53', 'X57'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 49.355 \t RMSE (SP): 82.144 \t RMSE (NO): 24.947 \t RMSE BEST: 46.628\t76.574\t24.947\n",
      "COMB:(('X28', 'X33', 'X40', 'X44', 'X53', 'X57', 'X58'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 72.828 \t RMSE (SP): 128.196 \t RMSE (NO): 24.947 \t RMSE BEST: 46.628\t76.574\t24.947\n",
      "COMB:(('X26', 'X35', 'X36', 'X37', 'X39', 'X56', 'X57'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 62.124 \t RMSE (SP): 107.496 \t RMSE (NO): 24.947 \t RMSE BEST: 46.628\t76.574\t24.947\n",
      "COMB:(('X26', 'X27', 'X35', 'X39', 'X40', 'X50', 'X53'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 49.501 \t RMSE (SP): 82.440 \t RMSE (NO): 24.947 \t RMSE BEST: 46.628\t76.574\t24.947\n",
      "COMB:(('X27', 'X28', 'X30', 'X34', 'X43', 'X46', 'X51'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 47.450 \t RMSE (SP): 78.261 \t RMSE (NO): 24.947 \t RMSE BEST: 46.628\t76.574\t24.947\n",
      "COMB:(('X24', 'X33', 'X44', 'X50', 'X52', 'X53', 'X55'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 68.738 \t RMSE (SP): 120.328 \t RMSE (NO): 24.947 \t RMSE BEST: 46.628\t76.574\t24.947\n",
      "COMB:(('X24', 'X27', 'X30', 'X44', 'X46', 'X49', 'X52'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 47.679 \t RMSE (SP): 78.731 \t RMSE (NO): 24.947 \t RMSE BEST: 46.628\t76.574\t24.947\n",
      "COMB:(('X37', 'X40', 'X46', 'X47', 'X49', 'X55', 'X60'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 59.534 \t RMSE (SP): 102.426 \t RMSE (NO): 24.947 \t RMSE BEST: 46.628\t76.574\t24.947\n",
      "COMB:(('X32', 'X33', 'X36', 'X37', 'X46', 'X48', 'X50'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 67.578 \t RMSE (SP): 118.087 \t RMSE (NO): 24.947 \t RMSE BEST: 46.628\t76.574\t24.947\n",
      "COMB:(('X28', 'X31', 'X35', 'X38', 'X41', 'X42', 'X50'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 55.440 \t RMSE (SP): 94.346 \t RMSE (NO): 24.947 \t RMSE BEST: 46.628\t76.574\t24.947\n",
      "COMB:(('X32', 'X36', 'X42', 'X44', 'X45', 'X54', 'X58'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 60.910 \t RMSE (SP): 105.124 \t RMSE (NO): 24.947 \t RMSE BEST: 46.628\t76.574\t24.947\n",
      "COMB:(('X32', 'X33', 'X40', 'X44', 'X46', 'X58', 'X59'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 73.131 \t RMSE (SP): 128.777 \t RMSE (NO): 24.947 \t RMSE BEST: 46.628\t76.574\t24.947\n",
      "COMB:(('X25', 'X27', 'X34', 'X41', 'X50', 'X53', 'X54'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 49.450 \t RMSE (SP): 82.336 \t RMSE (NO): 24.947 \t RMSE BEST: 46.628\t76.574\t24.947\n",
      "COMB:(('X32', 'X41', 'X44', 'X45', 'X47', 'X48', 'X54'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 63.236 \t RMSE (SP): 109.665 \t RMSE (NO): 24.947 \t RMSE BEST: 46.628\t76.574\t24.947\n",
      "COMB:(('X36', 'X37', 'X42', 'X45', 'X53', 'X59', 'X60'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 63.052 \t RMSE (SP): 109.307 \t RMSE (NO): 24.947 \t RMSE BEST: 46.628\t76.574\t24.947\n",
      "COMB:(('X26', 'X27', 'X29', 'X41', 'X43', 'X51', 'X57'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 53.989 \t RMSE (SP): 91.462 \t RMSE (NO): 24.947 \t RMSE BEST: 46.628\t76.574\t24.947\n",
      "COMB:(('X36', 'X40', 'X45', 'X46', 'X49', 'X50', 'X56'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 58.225 \t RMSE (SP): 99.852 \t RMSE (NO): 24.947 \t RMSE BEST: 46.628\t76.574\t24.947\n",
      "COMB:(('X29', 'X35', 'X43', 'X44', 'X49', 'X52', 'X54'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 52.195 \t RMSE (SP): 87.874 \t RMSE (NO): 24.947 \t RMSE BEST: 46.628\t76.574\t24.947\n",
      "COMB:(('X26', 'X29', 'X38', 'X46', 'X48', 'X57', 'X58'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 49.557 \t RMSE (SP): 82.554 \t RMSE (NO): 24.947 \t RMSE BEST: 46.628\t76.574\t24.947\n",
      "COMB:(('X31', 'X36', 'X37', 'X39', 'X42', 'X45', 'X56'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 58.692 \t RMSE (SP): 100.772 \t RMSE (NO): 24.947 \t RMSE BEST: 46.628\t76.574\t24.947\n",
      "COMB:(('X24', 'X32', 'X36', 'X38', 'X39', 'X50', 'X57'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 48.078 \t RMSE (SP): 79.546 \t RMSE (NO): 24.947 \t RMSE BEST: 46.628\t76.574\t24.947\n",
      "COMB:(('X25', 'X28', 'X34', 'X37', 'X42', 'X47', 'X51'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 53.576 \t RMSE (SP): 90.637 \t RMSE (NO): 24.947 \t RMSE BEST: 46.628\t76.574\t24.947\n",
      "COMB:(('X24', 'X30', 'X37', 'X39', 'X44', 'X48', 'X57'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 46.708 \t RMSE (SP): 76.739 \t RMSE (NO): 24.947 \t RMSE BEST: 46.628\t76.574\t24.947\n",
      "COMB:(('X25', 'X26', 'X29', 'X36', 'X37', 'X48', 'X50'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 48.889 \t RMSE (SP): 81.198 \t RMSE (NO): 24.947 \t RMSE BEST: 46.628\t76.574\t24.947\n",
      "COMB:(('X24', 'X31', 'X32', 'X37', 'X41', 'X47', 'X49'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 63.684 \t RMSE (SP): 110.536 \t RMSE (NO): 24.947 \t RMSE BEST: 46.628\t76.574\t24.947\n",
      "COMB:(('X25', 'X34', 'X39', 'X48', 'X49', 'X50', 'X56'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 49.965 \t RMSE (SP): 83.381 \t RMSE (NO): 24.947 \t RMSE BEST: 46.628\t76.574\t24.947\n",
      "COMB:(('X25', 'X29', 'X39', 'X43', 'X44', 'X50', 'X52'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 45.741 \t RMSE (SP): 74.746 \t RMSE (NO): 24.947 \t RMSE BEST: 46.628\t76.574\t24.947\n",
      "BEST MODEL FOUND\n",
      "COMB:(('X27', 'X32', 'X35', 'X40', 'X49', 'X51', 'X60'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 49.396 \t RMSE (SP): 82.227 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X30', 'X31', 'X33', 'X43', 'X46', 'X54', 'X56'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 63.775 \t RMSE (SP): 110.714 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X32', 'X35', 'X44', 'X47', 'X48', 'X55', 'X60'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 56.391 \t RMSE (SP): 96.233 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X29', 'X34', 'X35', 'X38', 'X41', 'X42', 'X50'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 58.819 \t RMSE (SP): 101.022 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X29', 'X33', 'X42', 'X43', 'X47', 'X55', 'X57'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 73.155 \t RMSE (SP): 128.823 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X24', 'X25', 'X27', 'X30', 'X31', 'X52', 'X54'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 47.148 \t RMSE (SP): 77.642 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X26', 'X32', 'X43', 'X46', 'X49', 'X54', 'X59'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 60.818 \t RMSE (SP): 104.943 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X29', 'X43', 'X45', 'X54', 'X55', 'X57', 'X58'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 52.571 \t RMSE (SP): 88.627 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X24', 'X25', 'X33', 'X37', 'X38', 'X58', 'X59'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 70.376 \t RMSE (SP): 123.483 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X27', 'X37', 'X39', 'X41', 'X48', 'X49', 'X55'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 61.872 \t RMSE (SP): 107.005 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X24', 'X28', 'X31', 'X38', 'X39', 'X48', 'X54'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 56.036 \t RMSE (SP): 95.528 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X25', 'X34', 'X38', 'X39', 'X49', 'X52', 'X58'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 48.489 \t RMSE (SP): 80.383 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X27', 'X31', 'X35', 'X44', 'X50', 'X54', 'X58'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 51.688 \t RMSE (SP): 86.856 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X25', 'X30', 'X37', 'X38', 'X52', 'X53', 'X55'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 46.481 \t RMSE (SP): 76.272 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X24', 'X29', 'X30', 'X32', 'X36', 'X47', 'X48'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 46.580 \t RMSE (SP): 76.475 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X34', 'X35', 'X37', 'X39', 'X41', 'X48', 'X50'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 62.008 \t RMSE (SP): 107.269 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X30', 'X36', 'X38', 'X39', 'X40', 'X54', 'X59'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 46.564 \t RMSE (SP): 76.442 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X24', 'X29', 'X41', 'X43', 'X48', 'X52', 'X54'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 59.401 \t RMSE (SP): 102.165 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X24', 'X34', 'X39', 'X43', 'X47', 'X55', 'X57'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 59.525 \t RMSE (SP): 102.409 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X25', 'X32', 'X43', 'X48', 'X51', 'X53', 'X58'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 56.135 \t RMSE (SP): 95.726 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X30', 'X32', 'X33', 'X34', 'X36', 'X39', 'X60'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 62.672 \t RMSE (SP): 108.566 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X25', 'X30', 'X31', 'X32', 'X33', 'X46', 'X57'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 64.938 \t RMSE (SP): 112.974 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X32', 'X35', 'X37', 'X41', 'X47', 'X48', 'X55'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 65.808 \t RMSE (SP): 114.661 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X26', 'X29', 'X35', 'X39', 'X41', 'X42', 'X46'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 59.699 \t RMSE (SP): 102.752 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X27', 'X30', 'X37', 'X38', 'X44', 'X48', 'X60'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 46.317 \t RMSE (SP): 75.934 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X40', 'X44', 'X50', 'X53', 'X55', 'X58', 'X59'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 56.379 \t RMSE (SP): 96.208 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X33', 'X37', 'X41', 'X42', 'X46', 'X52', 'X58'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 71.531 \t RMSE (SP): 125.706 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X29', 'X31', 'X32', 'X37', 'X49', 'X51', 'X52'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 55.814 \t RMSE (SP): 95.089 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X35', 'X36', 'X37', 'X46', 'X49', 'X55', 'X58'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 62.200 \t RMSE (SP): 107.645 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X27', 'X30', 'X31', 'X32', 'X34', 'X40', 'X48'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 46.198 \t RMSE (SP): 75.690 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X27', 'X31', 'X34', 'X43', 'X44', 'X52', 'X58'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 53.511 \t RMSE (SP): 90.507 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X34', 'X36', 'X41', 'X51', 'X53', 'X58', 'X60'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 65.969 \t RMSE (SP): 114.973 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X28', 'X30', 'X34', 'X41', 'X51', 'X56', 'X57'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 48.110 \t RMSE (SP): 79.610 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X29', 'X39', 'X41', 'X44', 'X45', 'X56', 'X57'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 52.801 \t RMSE (SP): 89.088 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X26', 'X34', 'X35', 'X41', 'X50', 'X54', 'X60'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 67.004 \t RMSE (SP): 116.977 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X25', 'X31', 'X34', 'X40', 'X47', 'X48', 'X49'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 55.158 \t RMSE (SP): 93.787 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X36', 'X37', 'X42', 'X46', 'X52', 'X53', 'X60'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 63.342 \t RMSE (SP): 109.870 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X25', 'X32', 'X33', 'X35', 'X36', 'X38', 'X40'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 71.844 \t RMSE (SP): 126.307 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X26', 'X29', 'X46', 'X47', 'X51', 'X55', 'X58'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 51.055 \t RMSE (SP): 85.582 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X24', 'X36', 'X38', 'X40', 'X41', 'X42', 'X56'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 61.540 \t RMSE (SP): 106.356 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X25', 'X27', 'X29', 'X40', 'X48', 'X52', 'X58'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 47.915 \t RMSE (SP): 79.212 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X30', 'X33', 'X41', 'X44', 'X55', 'X58', 'X60'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 61.743 \t RMSE (SP): 106.753 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X26', 'X27', 'X31', 'X41', 'X50', 'X55', 'X56'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 55.771 \t RMSE (SP): 95.004 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X33', 'X37', 'X46', 'X50', 'X51', 'X53', 'X56'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 67.761 \t RMSE (SP): 118.442 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X27', 'X46', 'X51', 'X53', 'X57', 'X59', 'X60'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 48.945 \t RMSE (SP): 81.312 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X27', 'X34', 'X36', 'X39', 'X40', 'X45', 'X58'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 52.268 \t RMSE (SP): 88.020 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X29', 'X33', 'X35', 'X40', 'X45', 'X46', 'X57'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 74.010 \t RMSE (SP): 130.463 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X30', 'X31', 'X36', 'X43', 'X48', 'X51', 'X55'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 46.781 \t RMSE (SP): 76.888 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X28', 'X31', 'X41', 'X46', 'X53', 'X55', 'X56'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 57.722 \t RMSE (SP): 98.861 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X29', 'X31', 'X35', 'X44', 'X46', 'X49', 'X51'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 56.213 \t RMSE (SP): 95.880 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X24', 'X27', 'X33', 'X36', 'X37', 'X41', 'X51'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 71.722 \t RMSE (SP): 126.073 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X35', 'X40', 'X41', 'X45', 'X49', 'X59', 'X60'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 55.745 \t RMSE (SP): 94.952 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X28', 'X37', 'X38', 'X42', 'X48', 'X56', 'X60'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 58.549 \t RMSE (SP): 100.490 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X26', 'X30', 'X39', 'X41', 'X42', 'X53', 'X59'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 46.966 \t RMSE (SP): 77.269 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X25', 'X30', 'X31', 'X34', 'X47', 'X51', 'X52'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 46.006 \t RMSE (SP): 75.293 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X27', 'X29', 'X33', 'X36', 'X40', 'X47', 'X54'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 70.942 \t RMSE (SP): 124.574 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X25', 'X28', 'X31', 'X37', 'X50', 'X52', 'X53'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 51.195 \t RMSE (SP): 85.863 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X27', 'X29', 'X32', 'X38', 'X46', 'X54', 'X57'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 49.147 \t RMSE (SP): 81.721 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X24', 'X29', 'X34', 'X38', 'X40', 'X41', 'X52'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 58.251 \t RMSE (SP): 99.905 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X24', 'X28', 'X38', 'X39', 'X42', 'X55', 'X60'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 57.012 \t RMSE (SP): 97.459 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X37', 'X41', 'X45', 'X51', 'X54', 'X56', 'X57'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 60.640 \t RMSE (SP): 104.595 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X26', 'X27', 'X29', 'X33', 'X34', 'X44', 'X45'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 69.674 \t RMSE (SP): 122.131 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X24', 'X29', 'X30', 'X31', 'X35', 'X42', 'X50'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 47.414 \t RMSE (SP): 78.188 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X24', 'X28', 'X34', 'X42', 'X43', 'X52', 'X57'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 59.634 \t RMSE (SP): 102.623 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X27', 'X40', 'X41', 'X45', 'X46', 'X47', 'X55'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 58.714 \t RMSE (SP): 100.815 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X26', 'X40', 'X41', 'X42', 'X50', 'X53', 'X57'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 60.378 \t RMSE (SP): 104.081 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X25', 'X34', 'X37', 'X39', 'X42', 'X56', 'X57'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 50.297 \t RMSE (SP): 84.051 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X26', 'X38', 'X40', 'X45', 'X51', 'X52', 'X58'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 51.634 \t RMSE (SP): 86.746 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X31', 'X44', 'X47', 'X49', 'X52', 'X56', 'X60'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 58.290 \t RMSE (SP): 99.980 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X26', 'X27', 'X42', 'X50', 'X54', 'X58', 'X60'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 51.763 \t RMSE (SP): 87.006 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X29', 'X34', 'X35', 'X47', 'X54', 'X55', 'X60'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 59.354 \t RMSE (SP): 102.073 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X28', 'X30', 'X41', 'X43', 'X48', 'X55', 'X59'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 49.640 \t RMSE (SP): 82.722 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X25', 'X28', 'X34', 'X45', 'X47', 'X48', 'X57'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 52.198 \t RMSE (SP): 87.880 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X25', 'X31', 'X33', 'X43', 'X45', 'X51', 'X58'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 72.017 \t RMSE (SP): 126.640 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X28', 'X33', 'X34', 'X40', 'X41', 'X59', 'X60'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 72.282 \t RMSE (SP): 127.148 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X25', 'X27', 'X33', 'X35', 'X39', 'X49', 'X52'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 69.476 \t RMSE (SP): 121.752 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X24', 'X27', 'X38', 'X41', 'X45', 'X56', 'X58'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 57.038 \t RMSE (SP): 97.513 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X28', 'X29', 'X31', 'X35', 'X50', 'X53', 'X58'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 54.507 \t RMSE (SP): 92.493 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X32', 'X40', 'X42', 'X44', 'X50', 'X51', 'X52'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 59.571 \t RMSE (SP): 102.499 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X29', 'X36', 'X38', 'X50', 'X52', 'X54', 'X56'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 50.836 \t RMSE (SP): 85.139 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X26', 'X41', 'X45', 'X46', 'X47', 'X49', 'X51'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 68.707 \t RMSE (SP): 120.269 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X24', 'X26', 'X30', 'X40', 'X41', 'X45', 'X56'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 47.058 \t RMSE (SP): 77.457 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X27', 'X29', 'X31', 'X33', 'X41', 'X50', 'X57'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 71.800 \t RMSE (SP): 126.223 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X25', 'X27', 'X34', 'X50', 'X52', 'X54', 'X58'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 47.374 \t RMSE (SP): 78.106 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X27', 'X33', 'X35', 'X36', 'X39', 'X40', 'X43'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 71.231 \t RMSE (SP): 125.128 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X25', 'X27', 'X35', 'X37', 'X43', 'X52', 'X54'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 49.989 \t RMSE (SP): 83.429 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X24', 'X26', 'X33', 'X35', 'X38', 'X39', 'X40'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 72.779 \t RMSE (SP): 128.102 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X24', 'X26', 'X27', 'X49', 'X51', 'X53', 'X60'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 50.565 \t RMSE (SP): 84.594 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X28', 'X30', 'X34', 'X36', 'X41', 'X42', 'X56'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 47.122 \t RMSE (SP): 77.590 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X25', 'X29', 'X32', 'X36', 'X39', 'X56', 'X60'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 48.818 \t RMSE (SP): 81.054 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X25', 'X28', 'X30', 'X38', 'X49', 'X52', 'X53'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 47.246 \t RMSE (SP): 77.844 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X26', 'X28', 'X29', 'X31', 'X39', 'X47', 'X53'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 55.844 \t RMSE (SP): 95.148 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X24', 'X25', 'X42', 'X43', 'X45', 'X48', 'X58'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 53.503 \t RMSE (SP): 90.491 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X27', 'X29', 'X31', 'X43', 'X53', 'X54', 'X60'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 50.595 \t RMSE (SP): 84.654 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X30', 'X31', 'X33', 'X45', 'X54', 'X58', 'X59'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 65.688 \t RMSE (SP): 114.428 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X26', 'X28', 'X30', 'X32', 'X35', 'X51', 'X57'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 46.322 \t RMSE (SP): 75.944 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X25', 'X31', 'X43', 'X49', 'X51', 'X53', 'X56'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 55.407 \t RMSE (SP): 94.282 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X25', 'X26', 'X40', 'X47', 'X52', 'X55', 'X58'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 54.941 \t RMSE (SP): 93.357 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X26', 'X28', 'X31', 'X34', 'X38', 'X40', 'X48'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 56.137 \t RMSE (SP): 95.729 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X25', 'X33', 'X38', 'X46', 'X52', 'X55', 'X60'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 71.847 \t RMSE (SP): 126.313 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X26', 'X27', 'X31', 'X40', 'X50', 'X56', 'X60'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 51.267 \t RMSE (SP): 86.008 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X25', 'X33', 'X34', 'X46', 'X50', 'X54', 'X55'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 68.069 \t RMSE (SP): 119.037 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X32', 'X34', 'X36', 'X38', 'X39', 'X47', 'X57'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 54.049 \t RMSE (SP): 91.581 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X30', 'X31', 'X36', 'X37', 'X39', 'X52', 'X53'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 45.756 \t RMSE (SP): 74.776 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X24', 'X32', 'X36', 'X51', 'X52', 'X55', 'X59'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 63.463 \t RMSE (SP): 110.106 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X27', 'X33', 'X37', 'X41', 'X46', 'X52', 'X57'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 73.835 \t RMSE (SP): 130.128 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X24', 'X25', 'X38', 'X40', 'X41', 'X58', 'X60'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 56.056 \t RMSE (SP): 95.569 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X25', 'X28', 'X38', 'X41', 'X49', 'X57', 'X60'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 52.145 \t RMSE (SP): 87.772 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X25', 'X33', 'X41', 'X44', 'X45', 'X50', 'X54'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 64.228 \t RMSE (SP): 111.594 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X25', 'X29', 'X34', 'X44', 'X52', 'X54', 'X57'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 47.415 \t RMSE (SP): 78.190 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X25', 'X29', 'X38', 'X39', 'X42', 'X48', 'X54'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 47.798 \t RMSE (SP): 78.973 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X34', 'X37', 'X38', 'X42', 'X47', 'X49', 'X50'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 59.154 \t RMSE (SP): 101.681 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X29', 'X32', 'X33', 'X45', 'X46', 'X55', 'X56'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 73.925 \t RMSE (SP): 130.299 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X24', 'X30', 'X33', 'X36', 'X41', 'X45', 'X51'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 62.680 \t RMSE (SP): 108.580 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X32', 'X39', 'X45', 'X48', 'X50', 'X55', 'X57'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 56.154 \t RMSE (SP): 95.763 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X25', 'X30', 'X35', 'X36', 'X44', 'X52', 'X54'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 46.123 \t RMSE (SP): 75.534 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X26', 'X28', 'X39', 'X41', 'X46', 'X50', 'X51'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 54.308 \t RMSE (SP): 92.097 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X26', 'X29', 'X33', 'X37', 'X38', 'X44', 'X59'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 72.920 \t RMSE (SP): 128.373 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n",
      "COMB:(('X29', 'X37', 'X42', 'X44', 'X52', 'X58', 'X59'), ('X2', 'X24', 'X33', 'X37')) \t RMSE (ALL): 59.379 \t RMSE (SP): 102.122 \t RMSE (NO): 24.947 \t RMSE BEST: 45.741\t74.746\t24.947\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     17\u001b[39m w = np.clip(w, \u001b[32m1.0\u001b[39m, np.percentile(w, \u001b[32m95\u001b[39m))\n\u001b[32m     19\u001b[39m spike_predict_model = RandomForestRegressor(\n\u001b[32m     20\u001b[39m     n_estimators=\u001b[32m1500\u001b[39m,\n\u001b[32m     21\u001b[39m     max_depth=\u001b[32m18\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     24\u001b[39m     n_jobs=-\u001b[32m1\u001b[39m\n\u001b[32m     25\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[43mspike_predict_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_sp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_sp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m test_feature_df = feature_engineering1(anomaly_test_df, SENSOR_COLS=SENSOR_COLS, LAGS=LAGS, WINS=WINS)\n\u001b[32m     29\u001b[39m spiked_pred = spike_predict_model.predict(test_feature_df)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Develop/ass-production-management2/.venv/lib/python3.12/site-packages/sklearn/base.py:1474\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1467\u001b[39m     estimator._validate_params()\n\u001b[32m   1469\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1470\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1471\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1472\u001b[39m     )\n\u001b[32m   1473\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1474\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Develop/ass-production-management2/.venv/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:479\u001b[39m, in \u001b[36mBaseForest.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    473\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.warm_start \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.estimators_) > \u001b[32m0\u001b[39m:\n\u001b[32m    474\u001b[39m     \u001b[38;5;66;03m# We draw from the random state to get the random state we\u001b[39;00m\n\u001b[32m    475\u001b[39m     \u001b[38;5;66;03m# would have got if we hadn't used a warm_start.\u001b[39;00m\n\u001b[32m    476\u001b[39m     random_state.randint(MAX_INT, size=\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.estimators_))\n\u001b[32m    478\u001b[39m trees = [\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_estimator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mappend\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    480\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[32m    481\u001b[39m ]\n\u001b[32m    483\u001b[39m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[32m    484\u001b[39m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[32m    485\u001b[39m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[32m    486\u001b[39m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[32m    487\u001b[39m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[32m    488\u001b[39m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[32m    489\u001b[39m trees = Parallel(\n\u001b[32m    490\u001b[39m     n_jobs=\u001b[38;5;28mself\u001b[39m.n_jobs,\n\u001b[32m    491\u001b[39m     verbose=\u001b[38;5;28mself\u001b[39m.verbose,\n\u001b[32m   (...)\u001b[39m\u001b[32m    507\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[32m    508\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Develop/ass-production-management2/.venv/lib/python3.12/site-packages/sklearn/ensemble/_base.py:145\u001b[39m, in \u001b[36mBaseEnsemble._make_estimator\u001b[39m\u001b[34m(self, append, random_state)\u001b[39m\n\u001b[32m    142\u001b[39m estimator.set_params(**{p: \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.estimator_params})\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m random_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m     \u001b[43m_set_random_states\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m append:\n\u001b[32m    148\u001b[39m     \u001b[38;5;28mself\u001b[39m.estimators_.append(estimator)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Develop/ass-production-management2/.venv/lib/python3.12/site-packages/sklearn/ensemble/_base.py:70\u001b[39m, in \u001b[36m_set_random_states\u001b[39m\u001b[34m(estimator, random_state)\u001b[39m\n\u001b[32m     68\u001b[39m random_state = check_random_state(random_state)\n\u001b[32m     69\u001b[39m to_set = {}\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m):\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m key == \u001b[33m\"\u001b[39m\u001b[33mrandom_state\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m key.endswith(\u001b[33m\"\u001b[39m\u001b[33m__random_state\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     72\u001b[39m         to_set[key] = random_state.randint(np.iinfo(np.int32).max)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Develop/ass-production-management2/.venv/lib/python3.12/site-packages/sklearn/base.py:243\u001b[39m, in \u001b[36mBaseEstimator.get_params\u001b[39m\u001b[34m(self, deep)\u001b[39m\n\u001b[32m    228\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    229\u001b[39m \u001b[33;03mGet parameters for this estimator.\u001b[39;00m\n\u001b[32m    230\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    240\u001b[39m \u001b[33;03m    Parameter names mapped to their values.\u001b[39;00m\n\u001b[32m    241\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    242\u001b[39m out = \u001b[38;5;28mdict\u001b[39m()\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_param_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    244\u001b[39m     value = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, key)\n\u001b[32m    245\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m deep \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(value, \u001b[33m\"\u001b[39m\u001b[33mget_params\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mtype\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Develop/ass-production-management2/.venv/lib/python3.12/site-packages/sklearn/base.py:208\u001b[39m, in \u001b[36mBaseEstimator._get_param_names\u001b[39m\u001b[34m(cls)\u001b[39m\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m []\n\u001b[32m    206\u001b[39m \u001b[38;5;66;03m# introspect the constructor arguments to find the model parameters\u001b[39;00m\n\u001b[32m    207\u001b[39m \u001b[38;5;66;03m# to represent\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m init_signature = \u001b[43minspect\u001b[49m\u001b[43m.\u001b[49m\u001b[43msignature\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[38;5;66;03m# Consider the constructor parameters excluding 'self'\u001b[39;00m\n\u001b[32m    210\u001b[39m parameters = [\n\u001b[32m    211\u001b[39m     p\n\u001b[32m    212\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m init_signature.parameters.values()\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m p.name != \u001b[33m\"\u001b[39m\u001b[33mself\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m p.kind != p.VAR_KEYWORD\n\u001b[32m    214\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/inspect.py:3348\u001b[39m, in \u001b[36msignature\u001b[39m\u001b[34m(obj, follow_wrapped, globals, locals, eval_str)\u001b[39m\n\u001b[32m   3346\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msignature\u001b[39m(obj, *, follow_wrapped=\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28mglobals\u001b[39m=\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mlocals\u001b[39m=\u001b[38;5;28;01mNone\u001b[39;00m, eval_str=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m   3347\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get a signature object for the passed callable.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3348\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSignature\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_wrapped\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_wrapped\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3349\u001b[39m \u001b[43m                                   \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_str\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_str\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/inspect.py:3085\u001b[39m, in \u001b[36mSignature.from_callable\u001b[39m\u001b[34m(cls, obj, follow_wrapped, globals, locals, eval_str)\u001b[39m\n\u001b[32m   3081\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   3082\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_callable\u001b[39m(\u001b[38;5;28mcls\u001b[39m, obj, *,\n\u001b[32m   3083\u001b[39m                   follow_wrapped=\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28mglobals\u001b[39m=\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mlocals\u001b[39m=\u001b[38;5;28;01mNone\u001b[39;00m, eval_str=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m   3084\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3085\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_signature_from_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigcls\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3086\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43mfollow_wrapper_chains\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_wrapped\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3087\u001b[39m \u001b[43m                                    \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_str\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_str\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/inspect.py:2597\u001b[39m, in \u001b[36m_signature_from_callable\u001b[39m\u001b[34m(obj, follow_wrapper_chains, skip_bound_arg, globals, locals, eval_str, sigcls)\u001b[39m\n\u001b[32m   2592\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m sig.replace(parameters=new_params)\n\u001b[32m   2594\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isfunction(obj) \u001b[38;5;129;01mor\u001b[39;00m _signature_is_functionlike(obj):\n\u001b[32m   2595\u001b[39m     \u001b[38;5;66;03m# If it's a pure Python function, or an object that is duck type\u001b[39;00m\n\u001b[32m   2596\u001b[39m     \u001b[38;5;66;03m# of a Python function (Cython functions, for instance), then:\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2597\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_signature_from_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43msigcls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2598\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43mskip_bound_arg\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip_bound_arg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2599\u001b[39m \u001b[43m                                    \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_str\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2601\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _signature_is_builtin(obj):\n\u001b[32m   2602\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _signature_from_builtin(sigcls, obj,\n\u001b[32m   2603\u001b[39m                                    skip_bound_arg=skip_bound_arg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/inspect.py:2488\u001b[39m, in \u001b[36m_signature_from_function\u001b[39m\u001b[34m(cls, func, skip_bound_arg, globals, locals, eval_str)\u001b[39m\n\u001b[32m   2482\u001b[39m     parameters.append(Parameter(name, annotation=annotation,\n\u001b[32m   2483\u001b[39m                                 kind=_VAR_KEYWORD))\n\u001b[32m   2485\u001b[39m \u001b[38;5;66;03m# Is 'func' is a pure Python function - don't validate the\u001b[39;00m\n\u001b[32m   2486\u001b[39m \u001b[38;5;66;03m# parameters list (for correct order and defaults), it should be OK.\u001b[39;00m\n\u001b[32m   2487\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(parameters,\n\u001b[32m-> \u001b[39m\u001b[32m2488\u001b[39m            return_annotation=\u001b[43mannotations\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mreturn\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_empty\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   2489\u001b[39m            __validate_parameters__=is_duck_function)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for (comb_A, comb_B) in comb_AB:\n",
    "    # スパイクモデルの学習\n",
    "    SENSOR_COLS = list(comb_A)\n",
    "    LAGS = [1, 2, 3, 5, 10, 20]\n",
    "    WINS = [3, 5, 10, 20]\n",
    "\n",
    "    train_feature_df = feature_engineering1(anomaly_train_df, SENSOR_COLS=SENSOR_COLS, LAGS=LAGS, WINS=WINS)\n",
    "\n",
    "    # スパイク部分の学習\n",
    "    X_sp = train_feature_df\n",
    "    y_sp = np.log1p(anomaly_train_df[\"OV\"].values)\n",
    "\n",
    "    # 高OVを重くする（まずは80%点を基準）\n",
    "    q = np.percentile(anomaly_train_df[\"OV\"].values, 90)  # “頂点”の境界\n",
    "    w = np.ones_like(anomaly_train_df[\"OV\"].values, dtype=float)\n",
    "    w[anomaly_train_df[\"OV\"].values >= q] = 1 + ((anomaly_train_df[\"OV\"].values[anomaly_train_df[\"OV\"].values >= q] / (q+1e-9))**3)\n",
    "    w = np.clip(w, 1.0, np.percentile(w, 95))\n",
    "\n",
    "    spike_predict_model1 = RandomForestRegressor(\n",
    "        n_estimators=1500,\n",
    "        max_depth=18,\n",
    "        min_samples_leaf=1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    spike_predict_model1.fit(X_sp, y_sp, sample_weight=w)\n",
    "\n",
    "    test_feature_df = feature_engineering1(anomaly_test_df, SENSOR_COLS=SENSOR_COLS, LAGS=LAGS, WINS=WINS)\n",
    "    spiked_pred = spike_predict_model1.predict(test_feature_df)\n",
    "    spiked_pred = np.expm1(spiked_pred)\n",
    "    spiked_pred_series = pd.Series(spiked_pred, index=anomaly_test_df.index)\n",
    "    rmse_sp = np.sqrt(mean_squared_error(anomaly_test_df[\"OV\"], spiked_pred))\n",
    "    #print(spiked_pred)\n",
    "\n",
    "    # フラット部分の学習\n",
    "    normal_features = [\n",
    "        # 時間系\n",
    "        \"elapsed_day\", \"duration_sec\", \"duration_log1p\",\n",
    "\n",
    "        # OVの過去特徴\n",
    "        \"OV_lag1\",\"OV_lag2\",\"OV_lag5\",\n",
    "        \"OV_diff1\",\"OV_roll_mean5\",\"OV_roll_std5\",\"OV_z5\",\n",
    "        \"OV_ema5\",\"OV_ema_dev5\",\n",
    "        \"OV_std_ratio_5_20\",\n",
    "\n",
    "        # バッチ内過去統計（追加）\n",
    "        \"pos_in_batch\",\n",
    "        \"OV_batch_exp_mean\",\"OV_batch_exp_std\",\"OV_batch_exp_max\",\"OV_batch_exp_min\",\n",
    "        \"OV_batch_roll_mean5\",\"OV_batch_roll_std5\",\n",
    "\n",
    "        # 使うセンサ（comb_Bなど）\n",
    "        *list(comb_B),\n",
    "\n",
    "        # target（学習dfには含める）\n",
    "        \"OV\"\n",
    "    ]\n",
    "    train_df= feature_engineering2(nomaly_train_df, normal_features)\n",
    "    test_df= feature_engineering2(normaly_test_df, normal_features)\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        #(\"scaler\", StandardScaler()),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", LGBMRegressor(\n",
    "            objective=\"regression\",\n",
    "            metric=\"rmse\",\n",
    "            verbose=-1,\n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "    train_X = train_df[normal_features].drop(columns=[\"OV\"])\n",
    "    pipeline.fit(train_X, train_df[\"OV\"])\n",
    "\n",
    "    test_X = test_df[normal_features].drop(columns=[\"OV\"])\n",
    "    normal_pred = pipeline.predict(test_X)\n",
    "    rmse_no = np.sqrt(mean_squared_error(normaly_test_df[\"OV\"], normal_pred))\n",
    "    normal_pred_series = pd.Series(normal_pred, index=normaly_test_df.index)\n",
    "    df_eval = pd.concat([test_df_original[\"OV\"].rename(\"y_true\"), spiked_pred_series.rename(\"y_pred\")], axis=1)\n",
    "    df_eval[\"y_pred\"] = df_eval[\"y_pred\"].fillna((normal_pred_series))\n",
    "    rmse_all = np.sqrt(mean_squared_error(df_eval[\"y_true\"], df_eval[\"y_pred\"]))\n",
    "    \n",
    "    print(f\"COMB:{comb_A, comb_B} \\t RMSE (ALL): {rmse_all:.3f} \\t RMSE (SP): {rmse_sp:.3f} \\t RMSE (NO): {rmse_no:.3f} \\t RMSE BEST: {best_rmse:.3f}\\t{best_rmse_sp:.3f}\\t{best_rmse_no:.3f}\")\n",
    "    if rmse_sp < best_rmse_sp:\n",
    "        best_rmse_sp = rmse_sp\n",
    "        best_comb_sp = (comb_A, comb_B)\n",
    "    if rmse_no < best_rmse_no:\n",
    "        best_rmse_no = rmse_no\n",
    "        best_comb_no = (comb_A, comb_B)\n",
    "    if rmse_all < best_rmse:\n",
    "        print(\"BEST MODEL FOUND\") \n",
    "        best_rmse = rmse_all\n",
    "        best_comb = (comb_A, comb_B)\n",
    "\n",
    "print(f\"best_comb: {best_comb} \\t RMSE (ALL): {best_rmse:.3f}\")\n",
    "print(f\"best_comb_sp: {best_comb_sp} \\t RMSE (SP): {best_rmse_sp:.3f}\")\n",
    "print(f\"best_comb_no: {best_comb_no} \\t RMSE (NO): {best_rmse_no:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3401ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_comb_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8eee676",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(\n",
    "    df_eval[\"y_true\"],\n",
    "    label=\"True OV\",\n",
    "    color=\"blue\",\n",
    "    alpha=0.5   \n",
    ")\n",
    "plt.plot(\n",
    "    df_eval[\"y_pred\"],\n",
    "    label=\"Predicted OV\",\n",
    "    color=\"red\",\n",
    "    alpha=0.5\n",
    ")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f807293c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
